{"cells": [{"cell_type": "markdown", "source": "# Boston Crime Analysis\n    In this notebook, the Boston crime data is analyzed from data stored in dashDB and the results are written back into dashDB\n\n##Overall, these are the steps involved in analyzing the data\n    1. Download the data from the Boston Open Data website as CSV and upload into dashDB \n    2. Read in the table containing Boston Crime statistics from dashDB\n    3. Analyze the data using Apache Spark\n    4. Store the analyzed results into a new table in dashDB\n\n  Datasets:\n      Crime statistics:\n      https://data.cityofboston.gov/Public-Safety/Crime-Incident-Reports/7cdf-6fgx \n      Police districts:\n      https://dataverse.harvard.edu/dataset.xhtml?id=2701204&versionId76395 \n     \n      ", "metadata": {}}, {"cell_type": "code", "source": "val sqlContext = new org.apache.spark.sql.SQLContext(sc)", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "import sqlContext.implicits._\nimport org.apache.spark.sql.functions._", "metadata": {"collapsed": true}, "execution_count": 2, "outputs": []}, {"cell_type": "markdown", "source": "### Add the dashDB data source by selecting 'Add Source' on the panel to the right\n### Select your dashDB instance\n\nSelect the dashDB 'Insert to code' in the box below to retrieve the parameters for dashDB to be replaced below\n", "metadata": {}}, {"cell_type": "code", "source": "port : \ndb : \nusername : \nssljdbcurl : \nhost :\nhttps_url :\ndsn : \nhostname : \njdbcurl : \nssldsn : \nuri : \npassword : \n\n", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "val crimeData_df = sqlContext.\n    load(\"jdbc\", \n    Map( \"url\" -> \"<jdbcurl>:user=<username>;password=<password>;\",\n    \"dbtable\" -> \"<schema>.CRIME_INCIDENT_REPORTS\"))\n\ncrimeData_df.count()\n", "metadata": {"collapsed": false}, "execution_count": 5, "outputs": []}, {"cell_type": "markdown", "source": "Filter out the non-district values from the DataFrame to clean up the data ", "metadata": {}}, {"cell_type": "code", "source": "val crimeDataCleaned_df = crimeData_df.select(crimeData_df(\"REPTDISTRICT\")).where(crimeData_df(\"REPTDISTRICT\") !== \"NULL\").where(crimeData_df(\"REPTDISTRICT\")!==\"HTU\").orderBy(\"REPTDISTRICT\") \ncrimeDataCleaned_df.count()", "metadata": {"collapsed": false}, "execution_count": 8, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 8, "data": {"text/plain": "267691"}}]}, {"cell_type": "markdown", "source": "Take an aggregate of total number of crimes by district\nRename the REPTDISTRICT to ID to match the key of District set", "metadata": {}}, {"cell_type": "code", "source": "val crimeDataTotals_df = crimeDataCleaned_df.groupBy(\"REPTDISTRICT\").agg(count(\"REPTDISTRICT\")).toDF(\"ID\", \"COUNT\")\ncrimeDataTotals_df.count()", "metadata": {"collapsed": false, "scrolled": true}, "execution_count": 9, "outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 9, "data": {"text/plain": "12"}}]}, {"cell_type": "markdown", "source": "Replace the parameters below with the appropriate dashDB properites\n\nCreate the table that will hold the result set", "metadata": {}}, {"cell_type": "code", "source": "import java.sql.DriverManager\nval jdbcClassName = \"com.ibm.db2.jcc.DB2Driver\"\nval jdbcurl=\"\" // enter the hostip from connection settings\nval user=\"\" // put the username from connection settings\nval password=\"\" // put the password from connection settings\nClass.forName(jdbcClassName)\nval connection = DriverManager.getConnection(jdbcurl, user, password)\nval stmt = connection.createStatement()\nprintln(\"Execute the statement:\\n\"+\n                    \"CREATE TABLE <schema>.BOSTONCRIME(\" +\n                    \"ID VARCHAR(10) ,\" +\n                    \"NUM INTEGER)\" )\n                  \nstmt.executeUpdate(\"CREATE TABLE <schema>.BOSTONCRIME(\" +\n                    \"ID VARCHAR(10) ,\" +\n                    \"NUM INTEGER)\")\n                     \nstmt.close()\nconnection.commit()", "metadata": {"collapsed": false, "scrolled": true}, "execution_count": 11, "outputs": [{"output_type": "stream", "text": "Execute the statement:\nCREATE TABLE DASH013602.BOSTONCRIME(ID VARCHAR(10) ,NUM INTEGER)\n", "name": "stdout"}]}, {"cell_type": "markdown", "source": "Write the result set into the dashDB table to be used downstream\nReplace <schema> with proper schema name", "metadata": {}}, {"cell_type": "code", "source": "val jdbcurl = \"\"\ncrimeDataTotals_df.insertIntoJDBC(jdbcurl, \"<schema>.BOSTONCRIME\", false)\nval GetFinalDataCount = sqlContext.jdbc(url = jdbcurl,\"<schema>.BOSTONCRIME\").show()", "metadata": {"collapsed": false}, "execution_count": 12, "outputs": [{"output_type": "stream", "text": "+---+-----+\n| ID|  NUM|\n+---+-----+\n| B2|40640|\n| A1|29653|\n|A15| 5621|\n| A7|12783|\n|D14|19520|\n| C6|20767|\n| B3|24812|\n| D4|37908|\n|E13|15167|\n| E5|12226|\n|E18|13985|\n|C11|34609|\n+---+-----+\n\n", "name": "stdout"}]}, {"cell_type": "code", "source": "", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}], "nbformat_minor": 0, "metadata": {"kernelspec": {"language": "scala", "name": "spark", "display_name": "Scala 2.10"}, "language_info": {"name": "scala"}}, "nbformat": 4}